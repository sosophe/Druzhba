{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/valentin.lapparov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_mystem(mapping, text=\"Текст нужно передать функции в виде строки!\"):\n",
    "    m = Mystem()\n",
    "    processed = m.analyze(text)\n",
    "    tagged = []\n",
    "    for w in processed:\n",
    "        try:\n",
    "            if w[\"analysis\"]:\n",
    "                lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "                pos = w[\"analysis\"][0][\"gr\"].split(\",\")[0]\n",
    "                pos = pos.split(\"=\")[0].strip()\n",
    "                #             print(lemma)\n",
    "                if lemma not in set(russian_stopwords):\n",
    "                    if pos in mapping:\n",
    "                        tagged.append(\n",
    "                            lemma + \"_\" + mapping[pos]\n",
    "                        )  # здесь мы конвертируем тэги\n",
    "                    else:\n",
    "                        tagged.append(\n",
    "                            lemma + \"_X\"\n",
    "                        )  # на случай, если попадется тэг, которого нет в маппинге\n",
    "            else:\n",
    "                continue\n",
    "        except KeyError:\n",
    "            continue  # я здесь пропускаю знаки препинания, но вы можете поступить по-другому\n",
    "    return tagged\n",
    "\n",
    "\n",
    "def get_words_embed(name, model, mapping):\n",
    "    res = []\n",
    "    stems = tag_mystem(text=name, mapping=mapping)\n",
    "    for word in stems:\n",
    "        try:\n",
    "            res.append(model.get_vector(word))\n",
    "        except:\n",
    "            print(word)\n",
    "            continue\n",
    "    return res\n",
    "\n",
    "\n",
    "def match_age_cat(text):\n",
    "    if text == \"0+\":\n",
    "        return [1, 1, 1, 1, 1]\n",
    "    elif text == \"6+\":\n",
    "        return [0, 1, 1, 1, 1]\n",
    "\n",
    "    elif text == \"12+\":\n",
    "        return [0, 0, 1, 1, 1]\n",
    "\n",
    "    elif text == \"16+\":\n",
    "        return [0, 0, 0, 1, 1]\n",
    "    else:\n",
    "        return [0, 0, 0, 0, 1]\n",
    "\n",
    "\n",
    "def compose_embedd_vector(words, age):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "\n",
    "    > words = np.array([[1, 2, 3], [-1, 0, 13], [0, 2, -3]])\n",
    "    > array([[ 1,  2,  3],\n",
    "             [-1,  0, 13],\n",
    "             [ 0,  2, -3]])\n",
    "\n",
    "    > age = np.array([1, 1, 1, 0, 0])\n",
    "    > array([1, 1, 1, 0, 0])\n",
    "\n",
    "    > compose_embedd_vector(words, age)\n",
    "    > array([-1,  0, -3,  1,  2, 13,  1,  1,  1,  0,  0])\n",
    "    \"\"\"\n",
    "    min_vec = words.min(axis=0)\n",
    "    max_vec = words.max(axis=0)\n",
    "    return np.concatenate((min_vec[0], max_vec[0], np.array(age)), axis=0)\n",
    "\n",
    "\n",
    "def get_top_workshops(interest, age_category, df_cats, word_model, mapping, top=10):\n",
    "    categories = df_cats.copy()\n",
    "    embeddings = []\n",
    "    age_category = np.array(match_age_cat(age_category))\n",
    "    for word in interest:\n",
    "        embeddings.append(get_words_embed(word, word_model, mapping))\n",
    "    average_embedding = compose_embedd_vector(\n",
    "        np.array(embeddings), np.array(age_category)\n",
    "    )\n",
    "    all_vectors = df_cats.iloc[:, 1:].values\n",
    "    categories[\"similarity\"] = word_model.cosine_similarities(\n",
    "        average_embedding, all_vectors\n",
    "    )\n",
    "    return (\n",
    "        (categories.sort_values(by=[\"similarity\"], ascending=False))\n",
    "        .name[:10]\n",
    "        .values.tolist()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_club_recommendations(\n",
    "    list_of_interests,\n",
    "    age,\n",
    "    topN=10,\n",
    "    club_categories_embedding_file=\"cats_embed.csv\",\n",
    "    master_clubs_file=\"кружки.csv\",\n",
    "):\n",
    "\n",
    "    model_file = \"180.zip\"  # model_url.split('/')[-1]\n",
    "    with zipfile.ZipFile(model_file, \"r\") as archive:\n",
    "        stream = archive.open(\"model.bin\")\n",
    "        word_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "            stream, binary=True\n",
    "        )\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map\"\n",
    "    mapping = {}\n",
    "    r = requests.get(url, stream=True)\n",
    "    for pair in r.text.split(\"\\n\"):\n",
    "        pair = re.sub(\"\\s+\", \" \", pair, flags=re.U).split(\" \")\n",
    "        if len(pair) > 1:\n",
    "            mapping[pair[0]] = pair[1]\n",
    "\n",
    "\n",
    "    df_cats = (\n",
    "        pd.read_csv(club_categories_embedding_file)\n",
    "        .T.reset_index()\n",
    "        .rename(columns={\"index\": \"name\"})\n",
    "    )\n",
    "\n",
    "    # df_cats = pd.read_pickle(v2).T.reset_index().rename(columns={'index':'name'})\n",
    "\n",
    "    workshops = get_top_workshops(\n",
    "        list_of_interests, \"12+\", df_cats, word_model, mapping, top=topN\n",
    "    )\n",
    "    df_master = pd.read_csv(master_clubs_file)\n",
    "    df_master[\"visited\"] = 1\n",
    "    df_ids = df_master[df_master.Наименование.isin(workshops)].id_ученика.unique()\n",
    "    df_users = (\n",
    "        df_master[df_master.id_ученика.isin(df_ids)]\n",
    "        .pivot_table(index=\"id_ученика\", columns=\"Наименование\", values=\"visited\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "    group_corrs = df_users.corr(method=\"pearson\", min_periods=80)\n",
    "    return group_corrs.sum().sort_values().reset_index()[-topN:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендация кружков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Рекоммендованные кружки:\n",
      "\n",
      "1) Физика\n",
      "2) Хореографическая подготовка\n",
      "3) Тхэквондо\n",
      "4) Музыкальный театр\n",
      "5) Теннис\n",
      "6) Иностранные языки\n",
      "7) Изобразительная деятельность\n",
      "8) Шахматы\n",
      "9) Английский язык\n",
      "10) Клуб кинолюбителя\n"
     ]
    }
   ],
   "source": [
    "result_circles = get_club_recommendations(\n",
    "    list_of_interests=[\"балет\", \"море\", \"солнце\"], age=\"16+\"\n",
    ")\n",
    "circle_df = pd.DataFrame(result_circles)\n",
    "i = 0\n",
    "print(\"Рекоммендованные кружки:\\n\")\n",
    "for _, row in circle_df.iterrows():\n",
    "    i += 1\n",
    "    title = str(row[\"Наименование\"])\n",
    "    if title == \"nan\":\n",
    "        title = \"\"\n",
    "    output = f\"{i}) \" + title\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
