{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import functools\n",
    "import pickle\n",
    "import string\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# To make things easier later, we're also importing numpy and pandas for\n",
    "# working with sample data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, linear_kernel\n",
    "\n",
    "# import pickle\n",
    "import re\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "\n",
    "\n",
    "table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "\n",
    "with open(\"raw_dict.pickle\", \"rb\") as pickle_in:\n",
    "    cat_to_vec = pickle.load(pickle_in)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-01 15:09:10.540 INFO    gensim.models.utils_any2vec: loading projection weights from <zipfile.ZipExtFile name='model.bin' mode='r' compress_type=deflate>\n",
      "2020-11-01 15:09:13.264 INFO    gensim.models.utils_any2vec: loaded (189193, 300) matrix from <zipfile.ZipExtFile [closed]>\n"
     ]
    }
   ],
   "source": [
    "def heavy_load():\n",
    "    database = pd.read_csv(\"database.csv\")\n",
    "    books = database.itemid.values.copy()\n",
    "    readers_birthday = pd.read_csv(\"readers_birthday.csv\")\n",
    "    algo = pickle.load(open(\"recom_model.pickle\", \"rb\"))\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    cluster_embedding = pickle.load(open(\"cluster_embedding.pickle\", \"rb\"))\n",
    "    cluster_embedd_data = pickle.load(open(\"cluster_embedd_data.pickle\", \"rb\"))\n",
    "    clean_description_data = pickle.load(open(\"clean_description.pickle\", \"rb\"))\n",
    "    event_type_embedding = pickle.load(open(\"event_type_embedding.pickle\", \"rb\"))\n",
    "    path = \"../final_data/Мероприятия.csv\"\n",
    "    events = pd.read_csv(\n",
    "        path,\n",
    "        usecols=[\n",
    "            \"Название мероприятия\",\n",
    "            \"Тип мероприятия\",\n",
    "            \"Направленность мероприятия\",\n",
    "            \"Краткое описание\",\n",
    "            \"Округ\",\n",
    "            \"Район\",\n",
    "            \"Возрастной ценз участников мероприятия\",\n",
    "            \"Возрастная категория\",\n",
    "        ],\n",
    "    )\n",
    "    merged = pd.merge(\n",
    "        events,\n",
    "        event_type_embedding,\n",
    "        on=\"Направленность мероприятия\",\n",
    "        suffixes=(\"\", \"_y\"),\n",
    "    )\n",
    "    model_file = \"180.zip\"  # model_url.split('/')[-1]\n",
    "    with zipfile.ZipFile(model_file, \"r\") as archive:\n",
    "        stream = archive.open(\"model.bin\")\n",
    "        word_model = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "            stream, binary=True\n",
    "        )\n",
    "    return (\n",
    "        database,\n",
    "        books,\n",
    "        readers_birthday,\n",
    "        algo,\n",
    "        stemmer,\n",
    "        cluster_embedding,\n",
    "        cluster_embedd_data,\n",
    "        clean_description_data,\n",
    "        event_type_embedding,\n",
    "        events,\n",
    "        merged,\n",
    "        stream,\n",
    "        word_model,\n",
    "    )\n",
    "\n",
    "\n",
    "(\n",
    "    database,\n",
    "    books,\n",
    "    readers_birthday,\n",
    "    algo,\n",
    "    stemmer,\n",
    "    cluster_embedding,\n",
    "    cluster_embedd_data,\n",
    "    clean_description_data,\n",
    "    event_type_embedding,\n",
    "    events,\n",
    "    merged,\n",
    "    stream,\n",
    "    word_model,\n",
    ") = heavy_load()\n",
    "\n",
    "\n",
    "def get_predictoins(input_iid, input_uid):\n",
    "    return algo.predict(uid=input_uid, iid=input_iid, verbose=False).est\n",
    "\n",
    "\n",
    "def get_books(input_uid):\n",
    "    with Pool(15) as p:\n",
    "        pred_rating = list(\n",
    "            p.map(functools.partial(get_predictoins, input_uid=input_uid), books)\n",
    "        )\n",
    "\n",
    "    pred_book = [(rating, book) for rating, book in zip(pred_rating, books)]\n",
    "\n",
    "    final_pred_books = [\n",
    "        x[1] for x in sorted(pred_book, key=lambda x: x[0], reverse=True)[:30]\n",
    "    ]\n",
    "    try:\n",
    "        user_age = (\n",
    "            readers_birthday[readers_birthday.userid == input_uid][\"age\"]\n",
    "        ).values[0]\n",
    "    except Exception as e:\n",
    "        user_age = 18\n",
    "\n",
    "    df = database[database.itemid.isin(final_pred_books)]\n",
    "\n",
    "    return df[(df.age_cat <= user_age)], user_age\n",
    "\n",
    "\n",
    "russian_stop_words = {\n",
    "    \"words\": [\n",
    "        \"а\",\n",
    "        \"е\",\n",
    "        \"и\",\n",
    "        \"ж\",\n",
    "        \"м\",\n",
    "        \"о\",\n",
    "        \"на\",\n",
    "        \"не\",\n",
    "        \"ни\",\n",
    "        \"об\",\n",
    "        \"но\",\n",
    "        \"он\",\n",
    "        \"мне\",\n",
    "        \"мои\",\n",
    "        \"мож\",\n",
    "        \"она\",\n",
    "        \"они\",\n",
    "        \"оно\",\n",
    "        \"мной\",\n",
    "        \"много\",\n",
    "        \"многочисленное\",\n",
    "        \"многочисленная\",\n",
    "        \"многочисленные\",\n",
    "        \"многочисленный\",\n",
    "        \"мною\",\n",
    "        \"мой\",\n",
    "        \"мог\",\n",
    "        \"могут\",\n",
    "        \"можно\",\n",
    "        \"может\",\n",
    "        \"можхо\",\n",
    "        \"мор\",\n",
    "        \"моя\",\n",
    "        \"моё\",\n",
    "        \"мочь\",\n",
    "        \"над\",\n",
    "        \"нее\",\n",
    "        \"оба\",\n",
    "        \"нам\",\n",
    "        \"нем\",\n",
    "        \"нами\",\n",
    "        \"ними\",\n",
    "        \"мимо\",\n",
    "        \"немного\",\n",
    "        \"одной\",\n",
    "        \"одного\",\n",
    "        \"менее\",\n",
    "        \"однажды\",\n",
    "        \"однако\",\n",
    "        \"меня\",\n",
    "        \"нему\",\n",
    "        \"меньше\",\n",
    "        \"ней\",\n",
    "        \"наверху\",\n",
    "        \"него\",\n",
    "        \"ниже\",\n",
    "        \"мало\",\n",
    "        \"надо\",\n",
    "        \"один\",\n",
    "        \"одиннадцать\",\n",
    "        \"одиннадцатый\",\n",
    "        \"назад\",\n",
    "        \"наиболее\",\n",
    "        \"недавно\",\n",
    "        \"миллионов\",\n",
    "        \"недалеко\",\n",
    "        \"между\",\n",
    "        \"низко\",\n",
    "        \"меля\",\n",
    "        \"нельзя\",\n",
    "        \"нибудь\",\n",
    "        \"непрерывно\",\n",
    "        \"наконец\",\n",
    "        \"никогда\",\n",
    "        \"никуда\",\n",
    "        \"нас\",\n",
    "        \"наш\",\n",
    "        \"нет\",\n",
    "        \"нею\",\n",
    "        \"неё\",\n",
    "        \"них\",\n",
    "        \"мира\",\n",
    "        \"наша\",\n",
    "        \"наше\",\n",
    "        \"наши\",\n",
    "        \"ничего\",\n",
    "        \"начала\",\n",
    "        \"нередко\",\n",
    "        \"несколько\",\n",
    "        \"обычно\",\n",
    "        \"опять\",\n",
    "        \"около\",\n",
    "        \"мы\",\n",
    "        \"ну\",\n",
    "        \"нх\",\n",
    "        \"от\",\n",
    "        \"отовсюду\",\n",
    "        \"особенно\",\n",
    "        \"нужно\",\n",
    "        \"очень\",\n",
    "        \"отсюда\",\n",
    "        \"в\",\n",
    "        \"во\",\n",
    "        \"вон\",\n",
    "        \"вниз\",\n",
    "        \"внизу\",\n",
    "        \"вокруг\",\n",
    "        \"вот\",\n",
    "        \"восемнадцать\",\n",
    "        \"восемнадцатый\",\n",
    "        \"восемь\",\n",
    "        \"восьмой\",\n",
    "        \"вверх\",\n",
    "        \"вам\",\n",
    "        \"вами\",\n",
    "        \"важное\",\n",
    "        \"важная\",\n",
    "        \"важные\",\n",
    "        \"важный\",\n",
    "        \"вдали\",\n",
    "        \"везде\",\n",
    "        \"ведь\",\n",
    "        \"вас\",\n",
    "        \"ваш\",\n",
    "        \"ваша\",\n",
    "        \"ваше\",\n",
    "        \"ваши\",\n",
    "        \"впрочем\",\n",
    "        \"весь\",\n",
    "        \"вдруг\",\n",
    "        \"вы\",\n",
    "        \"все\",\n",
    "        \"второй\",\n",
    "        \"всем\",\n",
    "        \"всеми\",\n",
    "        \"времени\",\n",
    "        \"время\",\n",
    "        \"всему\",\n",
    "        \"всего\",\n",
    "        \"всегда\",\n",
    "        \"всех\",\n",
    "        \"всею\",\n",
    "        \"всю\",\n",
    "        \"вся\",\n",
    "        \"всё\",\n",
    "        \"всюду\",\n",
    "        \"г\",\n",
    "        \"год\",\n",
    "        \"говорил\",\n",
    "        \"говорит\",\n",
    "        \"года\",\n",
    "        \"году\",\n",
    "        \"где\",\n",
    "        \"да\",\n",
    "        \"ее\",\n",
    "        \"за\",\n",
    "        \"из\",\n",
    "        \"ли\",\n",
    "        \"же\",\n",
    "        \"им\",\n",
    "        \"до\",\n",
    "        \"по\",\n",
    "        \"ими\",\n",
    "        \"под\",\n",
    "        \"иногда\",\n",
    "        \"довольно\",\n",
    "        \"именно\",\n",
    "        \"долго\",\n",
    "        \"позже\",\n",
    "        \"более\",\n",
    "        \"должно\",\n",
    "        \"пожалуйста\",\n",
    "        \"значит\",\n",
    "        \"иметь\",\n",
    "        \"больше\",\n",
    "        \"пока\",\n",
    "        \"ему\",\n",
    "        \"имя\",\n",
    "        \"пор\",\n",
    "        \"пора\",\n",
    "        \"потом\",\n",
    "        \"потому\",\n",
    "        \"после\",\n",
    "        \"почему\",\n",
    "        \"почти\",\n",
    "        \"посреди\",\n",
    "        \"ей\",\n",
    "        \"два\",\n",
    "        \"две\",\n",
    "        \"двенадцать\",\n",
    "        \"двенадцатый\",\n",
    "        \"двадцать\",\n",
    "        \"двадцатый\",\n",
    "        \"двух\",\n",
    "        \"его\",\n",
    "        \"дел\",\n",
    "        \"или\",\n",
    "        \"без\",\n",
    "        \"день\",\n",
    "        \"занят\",\n",
    "        \"занята\",\n",
    "        \"занято\",\n",
    "        \"заняты\",\n",
    "        \"действительно\",\n",
    "        \"давно\",\n",
    "        \"девятнадцать\",\n",
    "        \"девятнадцатый\",\n",
    "        \"девять\",\n",
    "        \"девятый\",\n",
    "        \"даже\",\n",
    "        \"алло\",\n",
    "        \"жизнь\",\n",
    "        \"далеко\",\n",
    "        \"близко\",\n",
    "        \"здесь\",\n",
    "        \"дальше\",\n",
    "        \"для\",\n",
    "        \"лет\",\n",
    "        \"зато\",\n",
    "        \"даром\",\n",
    "        \"первый\",\n",
    "        \"перед\",\n",
    "        \"затем\",\n",
    "        \"зачем\",\n",
    "        \"лишь\",\n",
    "        \"десять\",\n",
    "        \"десятый\",\n",
    "        \"ею\",\n",
    "        \"её\",\n",
    "        \"их\",\n",
    "        \"бы\",\n",
    "        \"еще\",\n",
    "        \"при\",\n",
    "        \"был\",\n",
    "        \"про\",\n",
    "        \"процентов\",\n",
    "        \"против\",\n",
    "        \"просто\",\n",
    "        \"бывает\",\n",
    "        \"бывь\",\n",
    "        \"если\",\n",
    "        \"люди\",\n",
    "        \"была\",\n",
    "        \"были\",\n",
    "        \"было\",\n",
    "        \"будем\",\n",
    "        \"будет\",\n",
    "        \"будете\",\n",
    "        \"будешь\",\n",
    "        \"прекрасно\",\n",
    "        \"буду\",\n",
    "        \"будь\",\n",
    "        \"будто\",\n",
    "        \"будут\",\n",
    "        \"ещё\",\n",
    "        \"пятнадцать\",\n",
    "        \"пятнадцатый\",\n",
    "        \"друго\",\n",
    "        \"другое\",\n",
    "        \"другой\",\n",
    "        \"другие\",\n",
    "        \"другая\",\n",
    "        \"других\",\n",
    "        \"есть\",\n",
    "        \"пять\",\n",
    "        \"быть\",\n",
    "        \"лучше\",\n",
    "        \"пятый\",\n",
    "        \"к\",\n",
    "        \"ком\",\n",
    "        \"конечно\",\n",
    "        \"кому\",\n",
    "        \"кого\",\n",
    "        \"когда\",\n",
    "        \"которой\",\n",
    "        \"которого\",\n",
    "        \"которая\",\n",
    "        \"которые\",\n",
    "        \"который\",\n",
    "        \"которых\",\n",
    "        \"кем\",\n",
    "        \"каждое\",\n",
    "        \"каждая\",\n",
    "        \"каждые\",\n",
    "        \"каждый\",\n",
    "        \"кажется\",\n",
    "        \"как\",\n",
    "        \"какой\",\n",
    "        \"какая\",\n",
    "        \"кто\",\n",
    "        \"кроме\",\n",
    "        \"куда\",\n",
    "        \"кругом\",\n",
    "        \"с\",\n",
    "        \"т\",\n",
    "        \"у\",\n",
    "        \"я\",\n",
    "        \"та\",\n",
    "        \"те\",\n",
    "        \"уж\",\n",
    "        \"со\",\n",
    "        \"то\",\n",
    "        \"том\",\n",
    "        \"снова\",\n",
    "        \"тому\",\n",
    "        \"совсем\",\n",
    "        \"того\",\n",
    "        \"тогда\",\n",
    "        \"тоже\",\n",
    "        \"собой\",\n",
    "        \"тобой\",\n",
    "        \"собою\",\n",
    "        \"тобою\",\n",
    "        \"сначала\",\n",
    "        \"только\",\n",
    "        \"уметь\",\n",
    "        \"тот\",\n",
    "        \"тою\",\n",
    "        \"хорошо\",\n",
    "        \"хотеть\",\n",
    "        \"хочешь\",\n",
    "        \"хоть\",\n",
    "        \"хотя\",\n",
    "        \"свое\",\n",
    "        \"свои\",\n",
    "        \"твой\",\n",
    "        \"своей\",\n",
    "        \"своего\",\n",
    "        \"своих\",\n",
    "        \"свою\",\n",
    "        \"твоя\",\n",
    "        \"твоё\",\n",
    "        \"раз\",\n",
    "        \"уже\",\n",
    "        \"сам\",\n",
    "        \"там\",\n",
    "        \"тем\",\n",
    "        \"чем\",\n",
    "        \"сама\",\n",
    "        \"сами\",\n",
    "        \"теми\",\n",
    "        \"само\",\n",
    "        \"рано\",\n",
    "        \"самом\",\n",
    "        \"самому\",\n",
    "        \"самой\",\n",
    "        \"самого\",\n",
    "        \"семнадцать\",\n",
    "        \"семнадцатый\",\n",
    "        \"самим\",\n",
    "        \"самими\",\n",
    "        \"самих\",\n",
    "        \"саму\",\n",
    "        \"семь\",\n",
    "        \"чему\",\n",
    "        \"раньше\",\n",
    "        \"сейчас\",\n",
    "        \"чего\",\n",
    "        \"сегодня\",\n",
    "        \"себе\",\n",
    "        \"тебе\",\n",
    "        \"сеаой\",\n",
    "        \"человек\",\n",
    "        \"разве\",\n",
    "        \"теперь\",\n",
    "        \"себя\",\n",
    "        \"тебя\",\n",
    "        \"седьмой\",\n",
    "        \"спасибо\",\n",
    "        \"слишком\",\n",
    "        \"так\",\n",
    "        \"такое\",\n",
    "        \"такой\",\n",
    "        \"такие\",\n",
    "        \"также\",\n",
    "        \"такая\",\n",
    "        \"сих\",\n",
    "        \"тех\",\n",
    "        \"чаще\",\n",
    "        \"четвертый\",\n",
    "        \"через\",\n",
    "        \"часто\",\n",
    "        \"шестой\",\n",
    "        \"шестнадцать\",\n",
    "        \"шестнадцатый\",\n",
    "        \"шесть\",\n",
    "        \"четыре\",\n",
    "        \"четырнадцать\",\n",
    "        \"четырнадцатый\",\n",
    "        \"сколько\",\n",
    "        \"сказал\",\n",
    "        \"сказала\",\n",
    "        \"сказать\",\n",
    "        \"ту\",\n",
    "        \"ты\",\n",
    "        \"три\",\n",
    "        \"эта\",\n",
    "        \"эти\",\n",
    "        \"что\",\n",
    "        \"это\",\n",
    "        \"чтоб\",\n",
    "        \"этом\",\n",
    "        \"этому\",\n",
    "        \"этой\",\n",
    "        \"этого\",\n",
    "        \"чтобы\",\n",
    "        \"этот\",\n",
    "        \"стал\",\n",
    "        \"туда\",\n",
    "        \"этим\",\n",
    "        \"этими\",\n",
    "        \"рядом\",\n",
    "        \"тринадцать\",\n",
    "        \"тринадцатый\",\n",
    "        \"этих\",\n",
    "        \"третий\",\n",
    "        \"тут\",\n",
    "        \"эту\",\n",
    "        \"суть\",\n",
    "        \"чуть\",\n",
    "        \"тысяч\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    words = text.split()\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    stripped = [w.translate(table).lower() for w in words]\n",
    "    removed = [\n",
    "        word for word in stripped if word not in set(russian_stop_words[\"words\"])\n",
    "    ]\n",
    "    stemmed = [stemmer.stem(word) for word in removed]\n",
    "    return \" \".join(stemmed)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def get_direction_set(request):\n",
    "    cl_embd_arr = np.array(\n",
    "        [element for element in event_type_embedding[\"embedd_vector\"].values]\n",
    "    )\n",
    "    X = np.concatenate((cl_embd_arr, request.reshape(-1, 605)))\n",
    "#     print(X.shape)\n",
    "    answer = [(idx, val) for idx, val in enumerate(cosine_similarity(X)[-1])]\n",
    "    answer = sorted(answer, key=lambda x: x[1], reverse=True)\n",
    "    answer_cluster = [i[0] for i in answer[1:3]]\n",
    "#     print(\"answer_cluster \", answer_cluster)\n",
    "#     print(\"event_type_embedding.shape = \", event_type_embedding.shape)\n",
    "#     print(\"event_type_embedding.reset_index() \", event_type_embedding.reset_index())\n",
    "    # idx_in_merged = (\n",
    "    #     event_type_embedding.reset_index().loc[answer_cluster, :][\"index\"].values\n",
    "    # )\n",
    "    # print(\"idx_in_merged \", idx_in_merged)\n",
    "    # directions = np.unique(merged.loc[idx_in_merged, :][\"Направленность мероприятия\"])\n",
    "    temp = event_type_embedding.reset_index()\n",
    "    idx_in_merged = temp[temp.index.isin(answer_cluster)][\"index\"].values\n",
    "#     print(\"idx_in_merged \", idx_in_merged)\n",
    "    directions = np.unique(\n",
    "        merged[merged.index.isin(idx_in_merged)][\"Направленность мероприятия\"]\n",
    "    )\n",
    "    return merged[merged[\"Направленность мероприятия\"].isin(directions)]\n",
    "\n",
    "\n",
    "def get_event(embed_vector, request_words, request_age):\n",
    "    hint_dir = get_direction_set(embed_vector)\n",
    "    direction = hint_dir.copy()\n",
    "    direction[\"low\"] = direction[\"Возрастная категория\"].apply(\n",
    "        lambda x: int(x.split()[1])\n",
    "    )\n",
    "    direction[\"high\"] = direction[\"Возрастная категория\"].apply(\n",
    "        lambda x: int(x.split()[3]) if len(x.split()) == 4 else 999\n",
    "    )\n",
    "    l = clean_description_data.iloc[\n",
    "        direction[\n",
    "            (direction.high >= request_age) & (direction.low <= request_age)\n",
    "        ].index\n",
    "    ].values.tolist()\n",
    "    tokenized_request = tokenize_text(\" \".join(request_words))\n",
    "    l.append(tokenized_request)\n",
    "    tfidf = TfidfVectorizer().fit_transform(l)\n",
    "    cosine_similarities = linear_kernel(tfidf[-1], tfidf).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[:-100:-1]\n",
    "    final_recommendation = list(related_docs_indices)\n",
    "    final_recommendation.remove(len(l) - 1)\n",
    "    return events.iloc[final_recommendation]\n",
    "\n",
    "\n",
    "# ## Рекомендация мероприятия\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def compose_embedd_vector(words, age):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "\n",
    "    > words = np.array([[1, 2, 3], [-1, 0, 13], [0, 2, -3]])\n",
    "    > array([[ 1,  2,  3],\n",
    "             [-1,  0, 13],\n",
    "             [ 0,  2, -3]])\n",
    "\n",
    "    > age = np.array([1, 1, 1, 0, 0])\n",
    "    > array([1, 1, 1, 0, 0])\n",
    "\n",
    "    > compose_embedd_vector(words, age)\n",
    "    > array([-1,  0, -3,  1,  2, 13,  1,  1,  1,  0,  0])\n",
    "    \"\"\"\n",
    "    min_vec = words.min(axis=0)\n",
    "    max_vec = words.max(axis=0)\n",
    "    return np.concatenate((min_vec, max_vec, age))\n",
    "\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "def tag_mystem(mapping, text=\"Текст нужно передать функции в виде строки!\"):\n",
    "    m = Mystem()\n",
    "    processed = m.analyze(text)\n",
    "    tagged = []\n",
    "    for w in processed:\n",
    "        try:\n",
    "            if w[\"analysis\"]:\n",
    "                lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "                pos = w[\"analysis\"][0][\"gr\"].split(\",\")[0]\n",
    "                pos = pos.split(\"=\")[0].strip()\n",
    "                #             print(lemma)\n",
    "                if lemma not in set(russian_stopwords):\n",
    "                    if pos in mapping:\n",
    "                        tagged.append(\n",
    "                            lemma + \"_\" + mapping[pos]\n",
    "                        )  # здесь мы конвертируем тэги\n",
    "                    else:\n",
    "                        tagged.append(\n",
    "                            lemma + \"_X\"\n",
    "                        )  # на случай, если попадется тэг, которого нет в маппинге\n",
    "            else:\n",
    "                continue\n",
    "        except KeyError:\n",
    "            continue  # я здесь пропускаю знаки препинания, но вы можете поступить по-другому\n",
    "    return tagged\n",
    "\n",
    "\n",
    "def get_words_embed(name, model, mapping):\n",
    "    res = []\n",
    "    stems = tag_mystem(text=name, mapping=mapping)\n",
    "    for word in stems:\n",
    "        try:\n",
    "            res.append(model.get_vector(word))\n",
    "        except:\n",
    "            print(word)\n",
    "            continue\n",
    "    return res\n",
    "\n",
    "\n",
    "def match_age_cat(text):\n",
    "    if text == \"0+\":\n",
    "        return [1, 1, 1, 1, 1]\n",
    "    elif text == \"6+\":\n",
    "        return [0, 1, 1, 1, 1]\n",
    "\n",
    "    elif text == \"12+\":\n",
    "        return [0, 0, 1, 1, 1]\n",
    "\n",
    "    elif text == \"16+\":\n",
    "        return [0, 0, 0, 1, 1]\n",
    "    else:\n",
    "        return [0, 0, 0, 0, 1]\n",
    "\n",
    "\n",
    "def get_top_workshops(interest, age_category, df_cats, word_model, mapping, top=10):\n",
    "    categories = df_cats.copy()\n",
    "    embeddings = []\n",
    "    age_category = np.array(match_age_cat(age_category))\n",
    "    for word in interest:\n",
    "        embeddings.append(get_words_embed(word, word_model, mapping))\n",
    "    # average_embedding = compose_embedd_vector_2(\n",
    "    #     np.array(embeddings), np.array(age_category)\n",
    "    # )\n",
    "    average_embedding = compose_embedd_vector_2(\n",
    "        embeddings, age_category\n",
    "    )\n",
    "    all_vectors = df_cats.iloc[:, 1:].values\n",
    "    categories[\"similarity\"] = word_model.cosine_similarities(\n",
    "        average_embedding, all_vectors\n",
    "    )\n",
    "    return (\n",
    "        (categories.sort_values(by=[\"similarity\"], ascending=False))\n",
    "        .name[:10]\n",
    "        .values.tolist()\n",
    "    )\n",
    "\n",
    "\n",
    "def get_club_recommendations(\n",
    "    list_of_interests,\n",
    "    age,\n",
    "    topN=10,\n",
    "    # word_model_file='word_model.pkl',\n",
    "    club_categories_embedding_file=\"cats_embed.csv\",\n",
    "    master_clubs_file=\"кружки.csv\",\n",
    "):\n",
    "    \n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map\"\n",
    "    mapping = {}\n",
    "    r = requests.get(url, stream=True)\n",
    "    for pair in r.text.split(\"\\n\"):\n",
    "        pair = re.sub(\"\\s+\", \" \", pair, flags=re.U).split(\" \")\n",
    "        if len(pair) > 1:\n",
    "            mapping[pair[0]] = pair[1]\n",
    "\n",
    "    # with open(club_categories_embedding_file,\"rb\") as pickle_in:\n",
    "    #     v2 = pickle.load(pickle_in)\n",
    "\n",
    "    df_cats = (\n",
    "        pd.read_csv(club_categories_embedding_file)\n",
    "        .T.reset_index()\n",
    "        .rename(columns={\"index\": \"name\"})\n",
    "    )\n",
    "\n",
    "    # df_cats = pd.read_pickle(v2).T.reset_index().rename(columns={'index':'name'})\n",
    "\n",
    "    workshops = get_top_workshops( #returns list\n",
    "        list_of_interests, age, df_cats, word_model, mapping, top=topN\n",
    "    )\n",
    "    df_master = pd.read_csv(master_clubs_file)\n",
    "    df_master[\"visited\"] = 1\n",
    "    df_ids = df_master[df_master.Наименование.isin(workshops)].id_ученика.unique()\n",
    "    df_users = (\n",
    "        df_master[df_master.id_ученика.isin(df_ids)]\n",
    "        .pivot_table(index=\"id_ученика\", columns=\"Наименование\", values=\"visited\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "    group_corrs = df_users.corr(method=\"pearson\", min_periods=80)\n",
    "    return group_corrs.sum().sort_values().reset_index()[-topN:]\n",
    "\n",
    "\n",
    "\n",
    "def compose_embedd_vector_2(words, age):\n",
    "    \"\"\"\n",
    "    Example:\n",
    "\n",
    "    > words = np.array([[1, 2, 3], [-1, 0, 13], [0, 2, -3]])\n",
    "    > array([[ 1,  2,  3],\n",
    "             [-1,  0, 13],\n",
    "             [ 0,  2, -3]])\n",
    "\n",
    "    > age = np.array([1, 1, 1, 0, 0])\n",
    "    > array([1, 1, 1, 0, 0])\n",
    "\n",
    "    > compose_embedd_vector(words, age)\n",
    "    > array([-1,  0, -3,  1,  2, 13,  1,  1,  1,  0,  0])\n",
    "    \"\"\"\n",
    "    words_unnest = [l[0] for l in list(words) if len(l) != 0]\n",
    "    min_vec = np.min(words_unnest, axis=0)\n",
    "    max_vec = np.max(words_unnest, axis=0)\n",
    "    return np.concatenate((min_vec, max_vec, np.array(age)), axis=0)\n",
    "\n",
    "def get_club_recommendations(\n",
    "    list_of_interests,\n",
    "    age,\n",
    "    topN=10,\n",
    "    # word_model_file='word_model.pkl',\n",
    "    club_categories_embedding_file=\"cats_embed.csv\",\n",
    "    master_clubs_file=\"кружки.csv\",\n",
    "):\n",
    "    \n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map\"\n",
    "    mapping = {}\n",
    "    r = requests.get(url, stream=True)\n",
    "    for pair in r.text.split(\"\\n\"):\n",
    "        pair = re.sub(\"\\s+\", \" \", pair, flags=re.U).split(\" \")\n",
    "        if len(pair) > 1:\n",
    "            mapping[pair[0]] = pair[1]\n",
    "\n",
    "    # with open(club_categories_embedding_file,\"rb\") as pickle_in:\n",
    "    #     v2 = pickle.load(pickle_in)\n",
    "\n",
    "    df_cats = (\n",
    "        pd.read_csv(club_categories_embedding_file)\n",
    "        .T.reset_index()\n",
    "        .rename(columns={\"index\": \"name\"})\n",
    "    )\n",
    "\n",
    "    # df_cats = pd.read_pickle(v2).T.reset_index().rename(columns={'index':'name'})\n",
    "\n",
    "    workshops = get_top_workshops(\n",
    "        list_of_interests, age, df_cats, word_model, mapping, top=topN\n",
    "    )\n",
    "    df_master = pd.read_csv(master_clubs_file)\n",
    "    df_master[\"visited\"] = 1\n",
    "    df_ids = df_master[df_master.Наименование.isin(workshops)].id_ученика.unique()\n",
    "    df_users = (\n",
    "        df_master[df_master.id_ученика.isin(df_ids)]\n",
    "        .pivot_table(index=\"id_ученика\", columns=\"Наименование\", values=\"visited\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "    group_corrs = df_users.corr(method=\"pearson\", min_periods=80)\n",
    "    return group_corrs.sum().sort_values().reset_index()[-topN:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Книги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_recommendation(user_input):\n",
    "    result_books, user_age = get_books(int(user_input))\n",
    "    print(\"Основываясь на ваших предпочтениях мы рекомендуем вам следующие книги:\")\n",
    "    i = 1\n",
    "    for _, row in result_books.iterrows():\n",
    "        author = str(row[\"author\"])\n",
    "        title = str(row[\"title\"])\n",
    "        if author == \"nan\":\n",
    "            author = \"\"\n",
    "        if title == \"nan\":\n",
    "            title = \"\"\n",
    "        output = f\"{i}) \" + author + ' \"' + title + '\"'\n",
    "        print(output)\n",
    "        i += 1\n",
    "        if i == 11:\n",
    "            break\n",
    "    key_words = result_books[\"category\"].unique()\n",
    "    request_words = [\n",
    "        w.translate(table).lower() for w in \" \".join(key_words).lower().split()\n",
    "    ]\n",
    "    request_input = np.array(\n",
    "        [cat_to_vec.get(key) for key in key_words if cat_to_vec.get(key) is not None]\n",
    "    )\n",
    "    if len(request_input) == 0:\n",
    "        embed_vector = np.array([0.5 for _ in range(605)])\n",
    "    else:\n",
    "        embed_vector = np.mean(request_input, axis=0)\n",
    "\n",
    "    return (\n",
    "        result_books,\n",
    "        user_age,\n",
    "        key_words,\n",
    "        request_words,\n",
    "        request_input,\n",
    "        embed_vector,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мероприятия "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_event_recomendations(result_events):\n",
    "    print(\"Возможно вам также будет интересно посетить данные мероприятия:\\n\")\n",
    "    i = 1\n",
    "    for _, row in result_events.iterrows():\n",
    "        descr = str(row[\"Краткое описание\"])\n",
    "        title = str(row[\"Название мероприятия\"])\n",
    "        discrict = str(row[\"Район\"])\n",
    "        area = str(row[\"Округ\"])\n",
    "        if descr == \"nan\":\n",
    "            descr = \"\"\n",
    "        if discrict == \"nan\":\n",
    "            discrict = \"\"\n",
    "        if area == \"nan\":\n",
    "            area = \"\"\n",
    "        if title == \"nan\":\n",
    "            title = \"\"\n",
    "        place = discrict + \", \" + area\n",
    "        age = str(row[\"Возрастной ценз участников мероприятия\"])\n",
    "        if age == \"nan\":\n",
    "            age = \"\"\n",
    "        output = f\"{i}) \" + '\"' + title + '\"' + \", \" + place + \" (\" + age + \")\"\n",
    "        output2 = f\"Краткое описание: \\t {descr}\\n\"\n",
    "        i += 1\n",
    "        print(output)\n",
    "        print(output2)\n",
    "        if i == 6:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кружки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_cat_age(age):\n",
    "    if age >= 18:\n",
    "        return \"18+\"\n",
    "    elif age >= 16:\n",
    "        return \"16+\"\n",
    "    elif age >= 12:\n",
    "        return \"12+\"\n",
    "    elif age >= 6:\n",
    "        return \"6+\"\n",
    "    else:\n",
    "        return \"0+\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_circles_recomendations(request_words, age_request_cat):\n",
    "    result_circles = get_club_recommendations(\n",
    "        list_of_interests=np.array(request_words), age=np.array(age_request_cat)\n",
    "    )\n",
    "    circle_df = pd.DataFrame(result_circles)\n",
    "    i = 0\n",
    "    st.subheader(\"Рекоммендованные кружки:\\n\")\n",
    "    for _, row in circle_df.iterrows():\n",
    "        i += 1\n",
    "        title = str(row[\"Наименование\"])\n",
    "        if title == \"nan\":\n",
    "            title = \"\"\n",
    "        output = f\"{i}) \" + title\n",
    "        print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Основываясь на ваших предпочтениях мы рекомендуем вам следующие книги:\n",
      "1) Рейнуотер Джанетт \"Москва - Лос-Анджелес, или Как выучить английский язык\"\n",
      "2)  \"Мамины и папины профессии\"\n",
      "3)  \"Моя первая энциклопедия\"\n",
      "4) Гиро Поль \"Быт и нравы древних римлян\"\n",
      "5) Грант Майкл \"Крушение Римской империи\"\n",
      "6) Беккер Карл Фридрих \"История Древнего мира: Древний Рим\"\n",
      "7) Уткин Анатолий Иванович \"Вторая мировая война\"\n",
      "8)  \"История Древнего мира. Античность\"\n",
      "9)  \"История Древнего мира. Античность\"\n",
      "10) Немировский Александр Иосифович \"История Древнего мира для школьников старших классов\"\n",
      "\n",
      "Возможно вам также будет интересно посетить данные мероприятия:\n",
      "\n",
      "1) \"Новогодний бал в Крыму\", ,  (18+)\n",
      "Краткое описание: \t Студия историко-бытового танца \"Ангаже\" Центра культуры и досуга \"Академический\" под руководством Марины Анатольевны Анисимовой на новогодних праздниках навестит прекрасный полуостров Крым. Первым в программе зимних каникул станет Новогодний бал, подготовленный участниками студии, в санатории \"Гурзуфский\".\n",
      "\n",
      "2) \"Мир вокруг нас\", Очаково-Матвеевское, Западный административный округ (6+)\n",
      "Краткое описание: \t В преддверии Дня заповедников и национальных парков в МКДЦ \"Планета молодых\" пройдёт лекционное мероприятие для младших классов. Ребята познакомятся с животным миром заповедников и парков нашего города.  Мероприятие направлено на обогащение знаний детей и воспитание правильного обращения с природными ресурсами. В конце программы ребят ждёт небольшой мастер-класс, на котором они смогут вместе с мас\n",
      "\n",
      "3) \"Музыкальная прогулка – «Хочу увидеть музыку»\", Бирюлёво Западное, Южный административный округ (12+)\n",
      "Краткое описание: \t Вокальная студия \"Созвездие\" посетит Российский национальный Музей Музыки. Российский национальный музей музыки (до 2018 года - Всероссийское музейное объединение музыкальной Основы музея заложила Московская консерватория, где постепенно в течение многих лет накапливались рукописи, нотные записи, партитуры, личные вещи музыкантов, их музыкальные инструменты, фотографии из музыкальных спектаклей.\n",
      "\n",
      "4) \"Геометрическая аппликация. Мастер-класс\", Бабушкинский, Северо-Восточный административный округ (0+)\n",
      "Краткое описание: \t ГБУК г. Москвы \"ММКЦ\" приглашает 14 января юных жителей Бабушкинского района от 4 лет на мастер-класс по геометрической аппликации. Геометрическая аппликация – умение создавать картинки в помощью простых геометрических фигур. Чтобы поделка получилась аккуратной, каждый участник потренируется вырезать фигуры с помощью специальных тренажеров\n",
      "\n",
      "5) \"Рождественские истории\", Очаково-Матвеевское, Западный административный округ (0+)\n",
      "Краткое описание: \t Клуб \"Дельфин\" приглашает в предпраздничный день на Рождественский кинопоказ. Мы познакомимся с добрым детским и поучительным фильмом \"Рождественские истории\".  Как понять свои ошибки? Как можно поменять себя? И как научиться принимать чужое мнение? Мы посмотрим фрагменты данного фильма, разберем и подискутируем, как же главный герой добился этого и встал на путь справедливости и чести.\n",
      "\n",
      "\n",
      "1) Коррекционно-развивающие занятия\n",
      "2) Актерское мастерство\n",
      "3) Социальная педагогика\n",
      "4) Художественная роспись\n",
      "5) Вокальный ансамбль\n",
      "6) Творческое развитие личности\n",
      "7) Умелые руки\n",
      "8) Общая физическая подготовка\n",
      "9) Музыка\n",
      "10) Игротека\n"
     ]
    }
   ],
   "source": [
    "user_input = \"123\"\n",
    "(\n",
    "    result_books,\n",
    "    user_age,\n",
    "    key_words,\n",
    "    request_words,\n",
    "    request_input,\n",
    "    embed_vector,\n",
    ") = get_book_recommendation(user_input)\n",
    "age_request_cat = match_cat_age(user_age)\n",
    "print()\n",
    "result_events = get_event(embed_vector, request_words, user_age)\n",
    "get_event_recomendations(result_events)\n",
    "print()\n",
    "get_circles_recomendations(request_words, age_request_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
